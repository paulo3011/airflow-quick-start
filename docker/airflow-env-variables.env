# On Linux, the quick-start needs to know your host user id and needs to have group id set to 0. Otherwise the files created in dags, logs and plugins will be created with root user ownership. You have to make sure to configure them for the docker-compose
# echo -e "AIRFLOW_UID=$(id -u)" > .env
AIRFLOW_UID=1000

AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@localhost:5432/airflow

# https://airflow.apache.org/docs/docker-stack/entrypoint.html (admin user)
# to upgrade the db and create admin users at entrypoint, so that you can start the webserver immediately
_AIRFLOW_DB_UPGRADE='true'
_AIRFLOW_WWW_USER_CREATE='true'
_AIRFLOW_WWW_USER_USERNAME=airflow
_AIRFLOW_WWW_USER_PASSWORD=airflow

AIRFLOW__CORE__FERNET_KEY=3DATZukBmfFWnw481LPSX0OdOP_Me7riYSVzmFT4rdU=
AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION='true'
AIRFLOW__CORE__LOAD_EXAMPLES='false'
AIRFLOW__API__AUTH_BACKENDS='airflow.api.auth.backend.default'

# update dags more often
AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=15

# https://airflow.apache.org/docs/apache-airflow/stable/configurations-ref.html#core
# The folder where your airflow pipelines live, most likely a subfolder in a code repository. This path must be absolute.
AIRFLOW__CORE__DAGS_FOLDER='/home/paulo/projects/paulo3011/airflow-quick-start/runtime/dags'
# Path to the folder containing Airflow plugins
AIRFLOW__CORE__PLUGINS_FOLDER='/home/paulo/projects/paulo3011/airflow-quick-start/runtime/plugins'